{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hebaallah2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rMYZg42buQKTNtu5jT7DsTR2QfXOASzk",
      "authorship_tag": "ABX9TyN3tTTKeDsBokjbVKWd8+E4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hebaallah61/AI_Project_objectdetection/blob/main/hebaallah2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmcUWbymfw_9"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras  \n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential #sequential model of nn\n",
        "from keras.layers import Dense,Flatten,Dropout #layers\n",
        "from keras.layers import Conv2D,MaxPool2D #conventional neural network\n",
        "from keras import backend as k # called keras as \n",
        "from keras import optimizers as opt"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muDdK6E9nNxz"
      },
      "source": [
        "batch_size=100\n",
        "num_classes=10\n",
        "epochs=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bRfIiwEh_IQ"
      },
      "source": [
        "img_rows ,img_columns=28,28\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbKX391cn6_u",
        "outputId": "cdd4c7b9-48e6-41a8-d2e7-cbc406cdd350"
      },
      "source": [
        "\n",
        "#preprocessing data (scalling,normalization,convert to binary classes)\n",
        "if k.image_data_format()=='channels_first': # scalling for data\n",
        "  x_train=x_train.reshape(x_train.shape[0],1,img_rows,img_columns)\n",
        "  x_test=x_test.reshape(x_test.shape[0],1,img_rows,img_columns)\n",
        "  input_shape=(1,img_rows,img_columns)\n",
        "else:\n",
        "  x_train=x_train.reshape(x_train.shape[0],1,img_rows,img_columns)\n",
        "  x_test=x_test.reshape(x_test.shape[0],1,img_rows,img_columns)\n",
        "  input_shape=(1,img_rows,img_columns)# channel 1 mean gray scalled\n",
        "#normalization for data \n",
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0\n",
        "print('x_train shap:',x_train.shape)\n",
        "print('x_test shap:',x_test.shape)\n",
        "\n",
        "# convert class vectors(classes of clothes) to binary class metices\n",
        "y_train=keras.utils.np_utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.np_utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shap: (60000, 1, 28, 28)\n",
            "x_test shap: (10000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2g7jkDqqR2v",
        "outputId": "b08ab67d-299d-469d-dc30-fa9955484220"
      },
      "source": [
        "#craete model\n",
        "model=Sequential()\n",
        "#first layer (convolutional layer,input layer)\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape, data_format='channels_first')) # 32 the number of filters,relu for all layers except output layer\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "#max pool layer\n",
        "model.add(MaxPool2D(pool_size=(2,2))) #2,2 size of pixels array\n",
        "model.add(Flatten()) # important function to make one dimention and ignore the others \n",
        "model.add(Dense(100,activation='relu'))# 128 number of neurns\n",
        "#output layer\n",
        "model.add(Dense(num_classes,activation='softmax'))# num of neurns=number of classes=10, softmax to make binary classification\n",
        "model.summary()\n",
        "#1- 26,26 the kernal subtract from 32 -3=26 \n",
        "#2= again subtract 26-3= 24\n",
        "#3-pooling divided\n",
        "#4-flatten remove dimention\n",
        "#5-128 neurn ,6= 10neurn in soft max"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 32, 26, 26)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 30, 24, 64)        15040     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 15, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 11520)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               1152100   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 1,168,470\n",
            "Trainable params: 1,168,470\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctBxfamYAxd1",
        "outputId": "1960b802-dba4-4520-b3ee-2f93879fdf29"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "opt=SGD(lr=0.01,momentum=0.9)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy\n",
        "              ,optimizer=opt\n",
        "              ,metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,batch_size=32,\n",
        "          epochs=10,\n",
        "          verbose=0,\n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2245f8c190>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3wiLq9nGmBY",
        "outputId": "3a2ab977-5530-41e2-e275-ed25df691481"
      },
      "source": [
        "score=model.evaluate(x_test,y_test,verbose=0)\n",
        "print('test loss',score[0])\n",
        "print('test accuracy',score[1])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss 0.034646350890398026\n",
            "test accuracy 0.9901999831199646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1gUbjFlHd5A",
        "outputId": "9bb0bf9a-a13a-4d95-f359-80b0a09c0327"
      },
      "source": [
        "model.save('model_final.h5')\n",
        "print('saved')"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeDjKe57JT00"
      },
      "source": [
        "**restore the model to make prediction **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHUYGf76I9gk",
        "outputId": "8f7bba7c-0d49-4e8a-f19c-8e4abf8d33ba"
      },
      "source": [
        "# make prediction for new img\n",
        "from keras.preprocessing.image import  load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "#load and prepar img \n",
        "def load_image(filename):\n",
        "  img=load_img(filename,\n",
        "               grayscale=True ,\n",
        "              target_size=(28,28)) \n",
        "  \n",
        "  img=img_to_array(img) # move image to array\n",
        "  #reshap the image to single sample with one channel\n",
        "  img=img.reshape(1,28,28,1)\n",
        "  #preparing to pixel data \n",
        "  img=img.astype('float32')\n",
        "  #normalization\n",
        "  img=img/255.0\n",
        "  return img \n",
        "\n",
        "#load img and predict the class\n",
        "def run_example():\n",
        "  #load img \n",
        "  img=load_img('/content/sample_image.png')\n",
        "  #load model\n",
        "  model=load_model('/content/model_final.h5')\n",
        "  #predict the class\n",
        "  #result=model.predict_classes(img) \n",
        "  result=  np.argmax(model.predict(x_test), axis=-1)\n",
        "  print(result[0])\n",
        "\n",
        "#entry point run the example\n",
        "run_example()\n",
        "\n",
        "\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    }
  ]
}